{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow\n",
    "\n",
    "# Helper packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn \n",
    "\n",
    "# Modeling process\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/mushrooms.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Since the dataset is categorical, and we want to perform a DNN model, we need to encode the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "data_en = data\n",
    "for i in data_en.columns.tolist():\n",
    "    data_en[i]= le.fit_transform(data_en[i])\n",
    "data_en.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now, we define `Y` to be the __class__ feature, which shows whether a certain mushroom is poisonous or edible based on the other features.\n",
    "##### Notice that in the definition of the set `X`, the __class__ feature is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data_en.iloc[:,1:23].values\n",
    "Y = data_en.iloc[:,0].values\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we initialize our model and add two hidden layers with respective units, 8 and 5, and a `Dropout`* layer and then an output layer.\n",
    "\n",
    "##### * `The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting. Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all inputs is unchanged.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialising DNN\n",
    "DNN = tensorflow.keras.models.Sequential()\n",
    "\n",
    "#Adding First Hidden Layer\n",
    "DNN.add(tensorflow.keras.layers.Dense(units=8,activation=\"relu\"))\n",
    "\n",
    "#Adding Second Hidden Layer\n",
    "DNN.add(tensorflow.keras.layers.Dense(units=5,activation=\"relu\"))\n",
    "\n",
    "#Adding Dropout Layer\n",
    "DNN.add(tensorflow.keras.layers.Dropout(0.2,input_shape=(2,)))\n",
    "\n",
    "#Adding Output Layer\n",
    "DNN.add(tensorflow.keras.layers.Dense(units=1,activation=\"sigmoid\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling DNN\n",
    "DNN.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After compiling the model, and before fitting it, it is nice to have an `EarlyStopping`* callback which makes the model stop training when a monitored metric has stopped improving.\n",
    "\n",
    "##### *Important arguments:\n",
    "`1- monitor: Quantity to be monitored, such as 'loss' or 'accuracy'.`\n",
    "\n",
    "`2- min_delta: Minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.`\n",
    "\n",
    "`3- patience: Number of epochs with no improvement after which training will be stopped.`\n",
    "\n",
    "`4- verbose: Verbosity mode, 0 or 1. Mode 0 is silent, and mode 1 displays messages when the callback takes an action.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting DNN\n",
    "my_c = tensorflow.keras.callbacks.EarlyStopping( monitor='loss', patience=2)\n",
    "DNN.fit(X_train,Y_train,batch_size=32,epochs = 100, callbacks=my_c, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next we interpret how well our model is performing, by investigating the confusion matrix, the classification report, the graph of the `ROC curve`*, and the area under the ROC curve.\n",
    "\n",
    "##### * `An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = DNN.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "print('*'*20)\n",
    "score, acc = DNN.evaluate(X_test, Y_test,\n",
    "                            batch_size=10)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)\n",
    "cm = confusion_matrix(Y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = DNN.predict(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, y_pred_proba)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.plot(fpr,tpr, label='ANN')\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC curve')\n",
    "plt.show()\n",
    "roc_auc_score(Y_test,y_pred_proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbc768028c3e6ead51d9a200ddcb2ec858ae62844dcd1994729a8279be9b48f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
